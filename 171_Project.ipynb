{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1a46628f-86d8-42fb-a0fd-32d77de74c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "86289bf9-9471-44fa-9dfc-d0aeb742eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the page to scrape\n",
    "url = 'https://basketball.realgm.com/international/league/1/Euroleague/players'\n",
    "\n",
    "# Send a GET request to fetch the page content\n",
    "response = requests.get(url)\n",
    "page_content = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6074ed6a-172b-4e64-b978-e11d8af4fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "388568ca-27d8-4dc5-a8aa-83dd4243ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table body (tbody) and all rows (tr) within it\n",
    "table_body = soup.find('tbody')\n",
    "rows = table_body.find_all('tr')\n",
    "\n",
    "players = []\n",
    "\n",
    "# Loop through each row (tr) to get player data\n",
    "for row in rows:\n",
    "    # Extract player data from each row\n",
    "    cells = row.find_all('td')\n",
    "    \n",
    "    # Extract player name from the first cell (assuming it is in an <a> tag)\n",
    "    name_tag = cells[0].find('a')  # Player name is assumed to be in the first cell inside <a> tag\n",
    "    if name_tag:\n",
    "        player_name = name_tag.get_text(strip=True)\n",
    "    else:\n",
    "        player_name = \"Unknown\"  # Default if name is missing\n",
    "    \n",
    "    # Extract height from the third column (height)\n",
    "    height = cells[2].get_text(strip=True)\n",
    "    \n",
    "    # Extract weight from the fourth column (weight)\n",
    "    weight = cells[3].get_text(strip=True)\n",
    "\n",
    "    # Store the player information\n",
    "    players.append({\n",
    "        'name': player_name,\n",
    "        'height': height,\n",
    "        'weight': weight\n",
    "    })\n",
    "\n",
    "# Print the scraped player data\n",
    "# for i in range(0,10):\n",
    "#     for player in players:\n",
    "#         print(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9171b5f2-370e-4aaa-8a8b-c3e7ec549f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the page to scrape for Player Stats\n",
    "url = 'https://basketball.realgm.com/international/league/1/Euroleague/stats'\n",
    "\n",
    "# Send a GET request to fetch the page content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "page_content = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7168e09d-00c9-466e-9a2b-5fe3a1d1b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first stats table on the page (this is the main stats table)\n",
    "table = soup.find('table')\n",
    "if not table:\n",
    "    raise Exception(\"Table not found on the page.\")\n",
    "\n",
    "# Get the table headers\n",
    "thead = table.find('thead')\n",
    "header_cells = thead.find_all('th')\n",
    "column_names = [cell.get_text(strip=True) for cell in header_cells]\n",
    "\n",
    "# Extract player rows\n",
    "tbody = table.find('tbody')\n",
    "rows = tbody.find_all('tr')\n",
    "\n",
    "player_stats = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) != len(column_names):\n",
    "        continue  # skip rows that don't match\n",
    "\n",
    "    player_data = {}\n",
    "    for i, cell in enumerate(cells):\n",
    "        if i == 0:\n",
    "            # Extract name from <a> tag if available\n",
    "            link = cell.find('a')\n",
    "            player_data[column_names[i]] = link.get_text(strip=True) if link else cell.get_text(strip=True)\n",
    "        else:\n",
    "            player_data[column_names[i]] = cell.get_text(strip=True)\n",
    "    player_stats.append(player_data)\n",
    "\n",
    "# Print each player's stats\n",
    "# for player in player_stats:\n",
    "#     print(player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1612854d-78da-4804-b9a3-203dd06f2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert height/weight data to a dictionary for faster lookup\n",
    "height_weight_map = {player['name']: {'height': player['height'], 'weight': player['weight']} for player in players}\n",
    "\n",
    "# Merge height and weight into the player_stats list\n",
    "for stat in player_stats:\n",
    "    name = stat['Player']\n",
    "    if name in height_weight_map:\n",
    "        stat['Height'] = height_weight_map[name]['height']\n",
    "        stat['Weight'] = height_weight_map[name]['weight']\n",
    "    else:\n",
    "        stat['Height'] = 'N/A'\n",
    "        stat['Weight'] = 'N/A'\n",
    "\n",
    "# Optionally: create a DataFrame and export to CSV (ONLY TO TEST IT)\n",
    "# df = pd.DataFrame(player_stats)\n",
    "# df.to_csv('euroleague_player_stats_with_height_weight.csv', index=False)\n",
    "\n",
    "# Or just print the merged data\n",
    "# for player in player_stats:\n",
    "#     print(player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "31043bf4-5ea1-4444-b808-19a58da2973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = []\n",
    "\n",
    "for year in range(2024, 1999, -1):\n",
    "    url = f'https://basketball.realgm.com/international/league/1/Euroleague/stats/{year}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    table = soup.find('table')\n",
    "    if not table:\n",
    "        continue\n",
    "\n",
    "    thead = table.find('thead')\n",
    "    header_cells = thead.find_all('th')\n",
    "    column_names = [cell.get_text(strip=True) for cell in header_cells]\n",
    "\n",
    "    tbody = table.find('tbody')\n",
    "    rows = tbody.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) != len(column_names):\n",
    "            continue\n",
    "\n",
    "        player_data = {'Season': year}\n",
    "        for i, cell in enumerate(cells):\n",
    "            text = cell.get_text(strip=True)\n",
    "            if i == 0:\n",
    "                link = cell.find('a')\n",
    "                player_data[column_names[i]] = link.get_text(strip=True) if link else text\n",
    "            else:\n",
    "                player_data[column_names[i]] = text\n",
    "\n",
    "        all_stats.append(player_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b9b566b8-cb91-495a-9f06-fed1377b7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert height/weight data to a dictionary for faster lookup\n",
    "height_weight_map = {player['name']: {'height': player['height'], 'weight': player['weight']} for player in players}\n",
    "\n",
    "# Merge height and weight into the all_stats list\n",
    "for stat in all_stats:\n",
    "    name = stat['Player']\n",
    "    if name in height_weight_map:\n",
    "        stat['Height'] = height_weight_map[name]['height']\n",
    "        stat['Weight'] = height_weight_map[name]['weight']\n",
    "    else:\n",
    "        stat['Height'] = 'N/A'\n",
    "        stat['Weight'] = 'N/A'\n",
    "\n",
    "# Convert the combined data to a DataFrame\n",
    "df = pd.DataFrame(all_stats)\n",
    "\n",
    "# Drop any row with N/A values\n",
    "df = df[~df.isin(['N/A']).any(axis=1)]\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "df.to_csv('latest_euroleague_player_stats_with_height_weight.csv', index=False)\n",
    "\n",
    "# Optionally, print the DataFrame\n",
    "# print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
